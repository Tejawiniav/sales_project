{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv(r'C:\\Users\\Rezwan86\\sales.csv')\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head(5)\n",
    "sales.tail(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['OrderDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 Jun 2017\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "date_string = \"21 Jun 2017\"\n",
    "# convert character to a date\n",
    "print(date_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[sales['Region']=='Central']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['TotalCost'] = sales['Units'] * sales['UnitCost']\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales['S.No'] = sales['S.No'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique method to retrive rows from a DataFrame\n",
    "# Rows can be extracted using an imaginary index position which isnâ€™t visible in the data frame.\n",
    "sales.iloc[10:15,2:5].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Units'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[sales['Region']=='Central']['Units'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean,median,nunique,max,min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[['Region','Units']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.loc[:,'Region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.drop('TotalCost',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming columns\n",
    "sales = sales.rename(columns={'Region':'Region wise','Item':'Item list'})\n",
    "sales.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using replace=TRUE\n",
    "#sales.rename(columns={'Region':'Territory','Item':'Product'},inplace=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.rename(columns=lambda x: x.replace(' ','_'),inplace=True)\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.to_csv(r'C:\\Users\\Administrator.acer-PC\\Desktop\\Python\\sales_python_version.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group_by(), agg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales\n",
    "sales.groupby(['Region_wise'])['Units'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales.groupby(['Region_wise','Item_list'])['Units'].sum()\n",
    "sales.groupby(['Item_list','Region_wise'])['Units'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.groupby(['Region_wise','Item_list'])['Units','UnitCost'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.groupby(['Region_wise','Item_list']).agg({'Units':'sum','UnitCost':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales.groupby(['Region_wise','Item_list']).agg({'Units':{'sum_units':'sum',\n",
    "                                                        'avg_units':'mean'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not practice\n",
    "sales['Date'] = pd.to_datetime(sales['OrderDate'],format='%m/%d/%Y')\n",
    "#sales['Date'].head()\n",
    "sales['weekday'] = sales['Date'].dt.strftime('%a')\n",
    "sales['weekday'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function crosstab in module pandas.core.reshape.pivot:\n",
      "\n",
      "crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, margins_name='All', dropna=True, normalize=False)\n",
      "    Compute a simple cross-tabulation of two (or more) factors. By default\n",
      "    computes a frequency table of the factors unless an array of values and an\n",
      "    aggregation function are passed\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    index : array-like, Series, or list of arrays/Series\n",
      "        Values to group by in the rows\n",
      "    columns : array-like, Series, or list of arrays/Series\n",
      "        Values to group by in the columns\n",
      "    values : array-like, optional\n",
      "        Array of values to aggregate according to the factors.\n",
      "        Requires `aggfunc` be specified.\n",
      "    rownames : sequence, default None\n",
      "        If passed, must match number of row arrays passed\n",
      "    colnames : sequence, default None\n",
      "        If passed, must match number of column arrays passed\n",
      "    aggfunc : function, optional\n",
      "        If specified, requires `values` be specified as well\n",
      "    margins : boolean, default False\n",
      "        Add row/column margins (subtotals)\n",
      "    margins_name : string, default 'All'\n",
      "        Name of the row / column that will contain the totals\n",
      "        when margins is True.\n",
      "    \n",
      "        .. versionadded:: 0.21.0\n",
      "    \n",
      "    dropna : boolean, default True\n",
      "        Do not include columns whose entries are all NaN\n",
      "    normalize : boolean, {'all', 'index', 'columns'}, or {0,1}, default False\n",
      "        Normalize by dividing all values by the sum of values.\n",
      "    \n",
      "        - If passed 'all' or `True`, will normalize over all values.\n",
      "        - If passed 'index' will normalize over each row.\n",
      "        - If passed 'columns' will normalize over each column.\n",
      "        - If margins is `True`, will also normalize margin values.\n",
      "    \n",
      "        .. versionadded:: 0.18.1\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    crosstab : DataFrame\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Any Series passed will have their name attributes used unless row or column\n",
      "    names for the cross-tabulation are specified.\n",
      "    \n",
      "    Any input passed containing Categorical data will have **all** of its\n",
      "    categories included in the cross-tabulation, even if the actual data does\n",
      "    not contain any instances of a particular category.\n",
      "    \n",
      "    In the event that there aren't overlapping indexes an empty DataFrame will\n",
      "    be returned.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([\"foo\", \"foo\", \"foo\", \"foo\", \"bar\", \"bar\",\n",
      "    ...               \"bar\", \"bar\", \"foo\", \"foo\", \"foo\"], dtype=object)\n",
      "    >>> b = np.array([\"one\", \"one\", \"one\", \"two\", \"one\", \"one\",\n",
      "    ...               \"one\", \"two\", \"two\", \"two\", \"one\"], dtype=object)\n",
      "    >>> c = np.array([\"dull\", \"dull\", \"shiny\", \"dull\", \"dull\", \"shiny\",\n",
      "    ...               \"shiny\", \"dull\", \"shiny\", \"shiny\", \"shiny\"],\n",
      "    ...               dtype=object)\n",
      "    \n",
      "    >>> pd.crosstab(a, [b, c], rownames=['a'], colnames=['b', 'c'])\n",
      "    ... # doctest: +NORMALIZE_WHITESPACE\n",
      "    b   one        two\n",
      "    c   dull shiny dull shiny\n",
      "    a\n",
      "    bar    1     2    1     0\n",
      "    foo    2     2    1     2\n",
      "    \n",
      "    >>> foo = pd.Categorical(['a', 'b'], categories=['a', 'b', 'c'])\n",
      "    >>> bar = pd.Categorical(['d', 'e'], categories=['d', 'e', 'f'])\n",
      "    >>> crosstab(foo, bar)  # 'c' and 'f' are not represented in the data,\n",
      "                            # and will not be shown in the output because\n",
      "                            # dropna is True by default. Set 'dropna=False'\n",
      "                            # to preserve categories with no data\n",
      "    ... # doctest: +SKIP\n",
      "    col_0  d  e\n",
      "    row_0\n",
      "    a      1  0\n",
      "    b      0  1\n",
      "    \n",
      "    >>> crosstab(foo, bar, dropna=False)  # 'c' and 'f' are not represented\n",
      "                            # in the data, but they still will be counted\n",
      "                            # and shown in the output\n",
      "    ... # doctest: +SKIP\n",
      "    col_0  d  e  f\n",
      "    row_0\n",
      "    a      1  0  0\n",
      "    b      0  1  0\n",
      "    c      0  0  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(sales['Rep'],sales['Units'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first dataframe\n",
    "raw_data = {\n",
    "        'subject_id': ['1', '2', '3', '4', '5'],\n",
    "        'first_name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'], \n",
    "        'last_name': ['Anderson', 'Ackerman', 'Ali', 'Aoni', 'Atiches']}\n",
    "df_a = pd.DataFrame(raw_data, columns = ['subject_id', 'first_name', 'last_name'])\n",
    "df_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second dataframe\n",
    "raw_data = {\n",
    "        'subject_id': ['4', '5', '6', '7', '8'],\n",
    "        'first_name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'], \n",
    "        'last_name': ['Bonder', 'Black', 'Balwner', 'Brice', 'Btisan']}\n",
    "df_b = pd.DataFrame(raw_data, columns = ['subject_id', 'first_name', 'last_name'])\n",
    "df_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#third dataframe\n",
    "raw_data = {\n",
    "        'subject_id': ['1', '2', '3', '4', '5', '7', '8', '9', '10', '11'],\n",
    "        'test_id': [51, 15, 15, 61, 16, 14, 15, 1, 61, 16]}\n",
    "df_n = pd.DataFrame(raw_data, columns = ['subject_id','test_id'])\n",
    "df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://chrisalbon.com/python/data_wrangling/pandas_join_merge_dataframe/\n",
    "#concatenation\n",
    "df_new = pd.concat([df_a, df_b])\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_a, df_b], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inner join\n",
    "pd.merge(df_new, df_n, on='subject_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_new, df_n, left_on='subject_id', right_on='subject_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_a, df_b, on='subject_id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_a, df_b, on='subject_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_a, df_b, on='subject_id', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_a, df_b, on='subject_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_a, df_b, on='subject_id', how='left', suffixes=('_df_a', '_df_b'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_a, df_b, right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_a,df_n,on='subject_id',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.where\n",
    "sales['Sales_Volume'] = np.where(sales['Units']>50,'High_Volume','Low_Volume')\n",
    "sales['Sales_Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(np.array([1,2,4,3,1,4,5,6,7,3,2]),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['sales_Volume_cut'] = pd.cut(sales['Units'],3,labels=['Low','Medium','High'])\n",
    "sales['sales_Volume_cut']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
